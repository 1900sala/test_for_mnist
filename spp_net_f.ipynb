{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import                                                                         \n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import math \n",
    "import sys\n",
    "from spp_layer import SPPLayer\n",
    "from read_data import *\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "SEED = 1356\n",
    "stddev = 0.05\n",
    "class SPPnet:\n",
    "    def __init__(self):\n",
    "        self.random_weight= False\n",
    "        self.wd = 5e-4\n",
    "        self.stddev = 0.05\n",
    "\n",
    "\n",
    "    def _conv_layer(self, bottom, name, shape=None):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "        \n",
    "            initW = tf.truncated_normal_initializer(stddev = self.stddev)\n",
    "            filter = tf.get_variable(name='filter', shape=shape, initializer=initW)  \n",
    "            initB = tf.constant_initializer(0.0)\n",
    "            conv_bias = tf.get_variable(name='bias',shape=shape[3], initializer=initB)\n",
    "            conv = tf.nn.conv2d(bottom, filter, strides=[1 ,1 ,1 ,1], padding='SAME')\n",
    "            relu = tf.nn.relu( tf.nn.bias_add(conv, conv_bias) )            \n",
    "            \n",
    "            return relu\n",
    "                \n",
    "    def _fc_layer(self, bottom, name, shape=None):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            if shape == None:\n",
    "                weight = self.get_fc_weight(name)\n",
    "                bias = self.get_bias(name)\n",
    "            else:\n",
    "                weight =self._variable_with_weight_decay(shape, self.stddev, self.wd)\n",
    "                initB = tf.constant_initializer(0.0)\n",
    "                bias = tf.get_variable(name='bias',shape=shape[1], initializer=initB)\n",
    "\n",
    "            fc = tf.nn.bias_add(tf.matmul(bottom, weight), bias)\n",
    "        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        %层数要改\n",
    "            if name == 'fc8' :\n",
    "                return fc   \n",
    "            else:\n",
    "                relu = tf.nn.relu(fc)\n",
    "                return relu\n",
    "        %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "        \n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    %卷积核，层数，bin的大小要改\n",
    "    def inference(self, data, train=True, num_class=1000):\n",
    "        with tf.name_scope('Processing'):\n",
    "            self.conv1_1 = self._conv_layer(data, 'conv1_1', [3,3,3,64])\n",
    "            self.conv1_2 = self._conv_layer(self.conv1_1, 'conv1_2', [3,3,64,64])\n",
    "            self.pool1 = tf.nn.max_pool(self.conv1_2, ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                    padding='SAME',name='pool1')\n",
    "\n",
    "            self.conv2_1 = self._conv_layer(self.pool1, 'conv2_1', [3,3,64,128])\n",
    "            self.conv2_2 = self._conv_layer(self.conv2_1, 'conv2_2', [3,3,128,128])\n",
    "            self.pool2 = tf.nn.max_pool(self.conv2_2, ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                    padding='SAME',name='pool2')\n",
    "\n",
    "            self.conv3_1 = self._conv_layer(self.pool2, 'conv3_1', [3,3,128,256])\n",
    "            self.conv3_2 = self._conv_layer(self.conv3_1, 'conv3_2', [3,3,256,256])\n",
    "            self.conv3_3 = self._conv_layer(self.conv3_2, 'conv3_3', [3,3,256,256])\n",
    "            self.pool3 = tf.nn.max_pool(self.conv3_3, ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                    padding='SAME',name='pool3')\n",
    "\n",
    "            self.conv4_1 = self._conv_layer(self.pool3, 'conv4_1', [3,3,256,512])\n",
    "            self.conv4_2 = self._conv_layer(self.conv4_1, 'conv4_2', [3,3,512, 512])\n",
    "            self.conv4_3 = self._conv_layer(self.conv4_2, 'conv4_3', [3,3,512,512])\n",
    "            self.pool4 = tf.nn.max_pool(self.conv4_3, ksize=[1,2,2,1],strides=[1,2,2,1],\n",
    "                    padding='SAME',name='pool4')\n",
    "            \n",
    "            self.conv5_1 = self._conv_layer(self.pool4, 'conv5_1', [3,3,512,512])\n",
    "            self.conv5_2 = self._conv_layer(self.conv5_1, 'conv5_2', [3,3,512,512])\n",
    "            self.conv5_3 = self._conv_layer(self.conv5_2, 'conv5_3', [3,3,512,512])\n",
    "            \n",
    "            bins = [3, 2, 1]\n",
    "            map_size = self.conv5_3.get_shape().as_list()[2]\n",
    "            print(self.conv5_3.get_shape())\n",
    "            sppLayer = SPPLayer(bins, map_size)\n",
    "            self.sppool = sppLayer.spatial_pyramid_pooling(self.conv5_3)\n",
    "            \n",
    "            numH = self.sppool.get_shape().as_list()[1]\n",
    "            print(numH)\n",
    "            self.fc6 = self._fc_layer(self.sppool, 'fc6', shape=[numH, 4096])\n",
    "            if train:\n",
    "                self.fc6 = tf.nn.dropout(self.fc6, 0.5, seed=SEED)\n",
    "            \n",
    "            self.fc7 = self._fc_layer(self.fc6, 'fc7',shape= [4096,4096])\n",
    "            if train:\n",
    "                self.fc7 = tf.nn.dropout(self.fc7, 0.5, seed=SEED)\n",
    "            self.fc8 = self._fc_layer(self.fc7, 'fc8', shape=[4096,num_class])\n",
    "            print('inference')\n",
    "            return self.fc8\n",
    "    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    \n",
    "    \n",
    "    def loss(self, logits, label=None):\n",
    "            self.pred = tf.nn.softmax(logits)\n",
    "            if label is not None:\n",
    "                label = tf.cast(label, tf.int64)\n",
    "                cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        logits, label, name = 'cross_entropy_all')\n",
    "                self.entropy_loss = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "#                tf.add_to_collection('losses', self.entropy_loss)\n",
    "#                self.all_loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "                \n",
    "                correct_prediction = tf.equal(tf.argmax(logits,1), label)\n",
    "                self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "                return (self.entropy_loss, self.accuracy)\n",
    "            else:\n",
    "                return self.pred\n",
    "    \n",
    "    def train(self, loss, global_step):\n",
    "        self.lr = tf.train.exponential_decay(self.lr, \n",
    "                global_step*self.batch_size, self.train_size*self.decay_epochs, 0.95, staircase=True)\n",
    "        self.optimizer = tf.train.MomentumOptimizer(self.lr, 0.9).minimize(loss,\n",
    "                global_step = global_step)\n",
    "        return (self.optimizer, self.lr)\n",
    "\n",
    "    def set_lr(self, lr, batch_size, train_size, decay_epochs = 10):\n",
    "        self.lr = lr\n",
    "        self.batch_size = batch_size\n",
    "        self.train_size = train_size\n",
    "        self.decay_epochs = decay_epochs\n",
    "\n",
    "    def _variable_with_weight_decay(self, shape, stddev, wd):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "        Note that the Variable is initialized with a truncated normal\n",
    "        distribution.\n",
    "        A weight decay is added only if one is specified.\n",
    "\n",
    "        Args:\n",
    "          name: name of the variable\n",
    "          shape: list of ints\n",
    "          stddev: standard deviation of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "              decay is not added for this Variable.\n",
    "\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        initializer = tf.truncated_normal_initializer(stddev=stddev)\n",
    "        var = tf.get_variable('weights', shape=shape,\n",
    "                              initializer=initializer)\n",
    "\n",
    "#        if wd and (not tf.get_variable_scope().reuse):\n",
    "#            weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "#            tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
